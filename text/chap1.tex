\chapter{Games with Team of Cooperative Agents}
\label{chap_mas}

\todo{Název kapitoly, koncepce}

\todo{Extraction from the related chapters from \ref{MAS2008}}

\todo{Neúplné algoritmy z DCOP článků}


\section{Perfect-Information Game}


\label{sec_perfect_information_game}

\todo{Převzato z MAS, doprovodný text}

\todo{Sladit značení a terminologii ve zbytku textu}

This thesis deals with the problem of coordination of agents in games. Before we will review
work on this topic and propose our algorithms, it is necessary to define what the game in our
context is. We will consider finite, discrete, full observable, deterministic and static
environment in which we will talk about \emph{perfect-information game}. Following definition
is based on the definition
proposed in \cite{MAS2008} and generalized for our purposes (original definition does not
include posibility of simultaneous play of multiple players and forces a play of exactly one
player).


\newtheorem*{defgpig}{Definition}
\begin{defgpig}[Perfect-information game]

A (finite) \textbf{perfect-information game} (in extensive form) is a tuple $G =
(P,A\cup\{\lambda\},S=S_n\cup S_p,\chi,\sigma,u)$, where:

\begin{itemize}

\item $P$ is a set of $n$ players;

\item $A$ is a (single) set of actions;

\item $S_n$ is a set of nonterminal choice states;

\item $S_t$ is a set of terminal states, disjoint from $S_n$;

\item $\chi: S_n \times P \mapsto 2^A \cup \{\lambda\} \setminus \varnothing$ is the action 
 function, which assigns to each choice node and player a set of possible actions, $\lambda \notin
 A$ is a neutral move played by the players not being on turn;

\item $\sigma: \{(s,a)| s \in S_n, a \in \prod\limits_{i\in P}\chi(s,i)\} \mapsto S$ is the
successor function, which maps a choice node and an action tuple to a new choice node or
terminal node such that for all $s_1, s_2 \in S_n$ and $a_1 \in \prod\limits_{i\in
P}\chi(s_1,i), a_2 \in \prod\limits_{i\in P}\chi(s_2,i)$, if 
$\sigma(s_1,a_1) = \sigma(s_2,a_2)$ then $s_1=s_2$ and $a_1=a_2$; and

\item $u = (u_1,\ldots,u_n)$, where $u_i: S_t \mapsto \mathbb{R}$ is a real-valued utility
function for player $i$ on the terminal nodes $S_t$.

\end{itemize}

We say that a perfect-information game is \textbf{turn-based} if each turn at most one player plays a
move, in other words, if the following restriction on the action function $\chi$ is satisfied:

\begin{equation}
\label{eq_turn_based_game}
\forall s \in S_n |\{i \in P|\chi(s,i) \not= \{\lambda\}\}| \le 1
\end{equation}

Contrariwise we will call a perfect-information game \textbf{simultaneous} if simultaneous
plays of multiple players are permitted and a state forcing a play of at least two players
exists (and so Equation \ref{eq_turn_based_game} is not satisfied).

\end{defgpig}

Because this thesis works only with perfect-information games, we will usually refer to
perfect-information game and its variants as to \emph{game}, \emph{turn-based game} and
\emph{simultaneous game}. We will also bound a utility function to $[0,1]$.

The aim of a player $i$ is reaching a terminal node $s$ with the greatest possible utility
$u_i(s)$.

\subsection{Conversion between Turn-Based and Simultaneous Games}
\label{sec_turn_based_game_conversion}

Because Monte-Carlo Tree Search requires turn-based games to ensure the convergence (as discussed in
section \ref{sec_minimax_convergence}) and our
algorithms, which are based on MCTS will be evaluated in the domain of naturally simultaneous game,
we will need a conversion from a turn-based game to a simultaneous game, which will be described
here.

We need to expand simultaneous moves to a sequence of single moves. To determine the order of such
an expansion, we can simply define linear ordering on a set of players. Then each simultaneous move
is splitted into multiple single-moves, one for each player, which is on turn.

There is, of course, a catch in this approach since the turn-based game created by this conversion
modifies game rules and adds advantage to players which plays later in originally simultaneous turn.
This is because players playing later have more information than in original simultaneous game
because they additionally know moves performed by players playing in same simultaneous turn.

In MCTS, when playing a simultaneous game, the calculated move will be commited to the simultaneous
game so the imbalance originating from the conversion will not affect the played game but only the
algorithm itself. We face the decision what ordering on players choose and we distinguish two main
variants - \emph{optimistic} and \emph{pesimistic expansion}. 

Optimistic expansion considers the
player performing MCTS calculation playing after all other players. This approach is called
optimistic because the player supposes that other players will play as he expect. On the other hand,
pesimistic expansion lets the player in MCTS calculations play first and gives other players
information about his move which is more pesimistic variant for the player.

\todo{Obrazek: rozdil optimistic x pesimistic expansion}
\todo{TODO}

\section{Team Coordination}

\subsection{Games with Teams of Players}

Definition of perferct-information game serves (without further modifications) as an
environment for \emph{teams of players}. A team of players (or simply a team) is a set of agents
attempting to reach the best result possible collectively. In other words, agents of a team
shares the utility. 

This can be simply applied to a perfect-information game. A team can be represented as a single
player of a perfect-information game where actions of such a player is joint-action composed of
all actions played by team members. The second possibility how to model a team in
perfect-information game is simply applying the definition of a team and considering players
with the same utility. Since it is more natural concept allowing the team player to be viewed as
independent agents, we will use this concept in our thesis. Following definition is a
formalization of the concept.

\todo{Sjednotit terminologii move vs. action}

\newtheorem*{defpigt}{Definition}
\begin{defpigt}[Perfect-information game with teams]

A (finite) \textbf{perfect-information game with Teams} (in extensive form) is a tuple $G =
(P,A\cup\{\lambda\}, S=S_n\cup S_p, \chi, \sigma, T, \tau, u)$, where:


\begin{itemize}

\item $P$, $n$, $A$, $\lambda$, $S$, $S_n$, $S_t$, $\chi$ and $\sigma$ are same as in
perfect-information game;

\item $T$ is a set of teams;

\item $\tau: P \mapsto T$, assigns players to the teams; and

\item $u = (u_1,\ldots,u_m)$, where $u_i: S_t \mapsto \mathbb{R}$ is a real-valued utility
function for team $i$ on the terminal nodes $S_t$.

\todo{Rozdíl mezi přístupy v předchozím odstavci, komunikace, ...}

\todo{Simultaneous game pro týmy (pure turn-based x turn-based x simultaneous)}

\end{itemize}

\end{defpigt}

A tuple of actions played by single team $T_a$ in state $S_b$ will be called \emph{joint-action} (formally
$(a_p^{S_b})_{\tau(p_a)=T_a}$).

\subsection{Communication}
\subsection{Distributed Constraints Optimization (??)}

\section{Conclusion}
